{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Words Similarity with Embeddings\n",
    "\n",
    "This tutorial explores the word similarities with respect to the learnt embeddings.\n",
    "\n",
    "The following are the steps of this tutorial:\n",
    "\n",
    "1. Implement Cosine similarity function\n",
    "2. Load learnt word embeddings\n",
    "3. Get top similar words given a word\n",
    "\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/ksalama/data2cooc2emb2ann/blob/master/text2emb/03-Explore_Word_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = './workspace'\n",
    "embeddings_file_path = os.path.join(WORKSPACE,'embeddings.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Consine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_consine_similarty(emb1, emb2):\n",
    "    return np.dot(emb1, emb2)/(np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embedding_file_path):\n",
    "    embedding_lookup = {}\n",
    "    with open(embeddings_file_path) as embedding_file:\n",
    "        for line in embedding_file:   \n",
    "            parts = line.split('\\t')\n",
    "            word = parts[0]\n",
    "            embedding = [float(v) for v in parts[1:]]\n",
    "            embedding_lookup[word] = embedding\n",
    "    return embedding_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4632"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_lookup = load_embeddings(embeddings_file_path)\n",
    "len(embedding_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Top Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_similar(word, k):\n",
    "    outputs = []\n",
    "    \n",
    "    input_word_embedding = embedding_lookup[word.lower()]\n",
    "    \n",
    "    for word in embedding_lookup:\n",
    "        embedding = embedding_lookup[word]\n",
    "        similarity = calculate_consine_similarty(input_word_embedding, embedding)\n",
    "        outputs.append((similarity, word))\n",
    "\n",
    "    return sorted(outputs, reverse=True)[:k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word: man\n",
      "==================\n",
      "['man', 'named', 'woman', 'person', 'boy', 'guy', 'young', 'girl', 'older', 'who']\n",
      "\n",
      "Input word: girl\n",
      "==================\n",
      "['girl', 'boy', 'woman', 'young', 'named', 'teenage', 'daughter', 'beautiful', 'man', 'sexy']\n",
      "\n",
      "Input word: happy\n",
      "==================\n",
      "['happy', 'quick', 'sad', 'horny', 'bored', 'believing', 'awake', 'listening', 'ending', 'roll']\n",
      "\n",
      "Input word: sad\n",
      "==================\n",
      "['sad', 'ending', 'happy', 'touching', 'sweet', 'regardless', 'truth', 'uplifting', 'incredibly', 'strangely']\n",
      "\n",
      "Input word: movie\n",
      "==================\n",
      "['movie', 'film', 'this', 'it', 'movies', 'horror', 'so', 'just', 'but', 'films']\n",
      "\n",
      "Input word: good\n",
      "==================\n",
      "['good', 'pretty', 'bad', 'very', 'great', 'job', 'decent', 'guy', 'funny', 'but']\n",
      "\n",
      "Input word: king\n",
      "==================\n",
      "['king', 'stephen', 'arthur', 'captain', 'jimmy', 'hopper', 'kennedy', 'eugene', 'george', 'philip']\n",
      "\n",
      "Input word: car\n",
      "==================\n",
      "['car', 'chase', 'chases', 'accident', 'crash', 'boat', 'crashes', 'driving', 'gun', 'foot']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = ['man', 'girl', 'happy', 'sad', 'movie', 'good', 'king', 'car']\n",
    "for word in words:\n",
    "    print(\"Input word: {}\".format(word))\n",
    "    print(\"==================\")\n",
    "    print([item[1] for item in top_similar(word, 10)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
